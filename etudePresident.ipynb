{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8bcbb3ab",
   "metadata": {},
   "source": [
    "# Rapport TAL\n",
    "## Partie Présidents\n",
    "Membres du binôme :\n",
    "- KRISNI Almehdi (3800519)\n",
    "- ARICHANDRA Santhos (3802651)\n",
    "\n",
    "### Introduction\n",
    "Dans cette partie, nous allons nous intéresser à la prédiction de l'interlocuteur lors d'un débat présidentiel entre Chirac et Mitterrand. Entre d'autres termes, qui a dit quoi ?\n",
    "\n",
    "Nous disposons donc d'une base de données d'apprentissage de 57000 lignes représentant un ensemble de phrases, chacune de ces dernières étiquetées par un C (Chirac) ou un M (Mitterrand), désignant la personne l'ayant prononcé. On peut alors labéliser notre ensemble d'apprentissage en 2 classes distinctes. \n",
    "\n",
    "Notre objectif est de mettre en place des algorithmes allant nous permettre de labelliser de nouveaux débats entre Chirac et Mitterrand.\n",
    "\n",
    "### Mise en place des import et des librairies utilisées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "15557cf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Pour retirer les messages d'alerte\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import codecs\n",
    "import re\n",
    "import os.path\n",
    "\n",
    "import copy\n",
    "\n",
    "# Librairies pour le traitement de texte\n",
    "import re\n",
    "import unicodedata\n",
    "import string\n",
    "\n",
    "# Librairie pour l'utilisation de compteurs\n",
    "from collections import Counter\n",
    "\n",
    "# Librairies pour le traitement de texte et la mise en place de vecteurs\n",
    "from sklearn.feature_extraction import text \n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "# Librairies pour la phase de Machine Learning\n",
    "import numpy as np\n",
    "import sklearn.naive_bayes as nb\n",
    "from sklearn import svm\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "# Libraire pour les statistiques (moyenne, ...)\n",
    "import statistics\n",
    "\n",
    "# Importation des librairies standards\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "\n",
    "# Importation de votre librairie iads\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "# Iportation de utils\n",
    "from iads import utils as ut\n",
    "\n",
    "# commande TRES utile pour recharger automatiquement le code que vous modifiez dans les modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04188d76",
   "metadata": {},
   "source": [
    "### Première analyse des données\n",
    "\n",
    "On extrait dans un premier les informations à la base de données d'apprentissage. On utilise la fonction d'extraction \"load_pres\" située dans le fichier utils.py.\n",
    "\n",
    "On considère 2 classes, la classe -1 représentant Mitterrand et la classe +1 représentant Chirac."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "79aa273d",
   "metadata": {},
   "outputs": [],
   "source": [
    "appdata = ut.load_pres(\"AFDpresidentutf8/corpus.tache1.learn.utf8\")\n",
    "appX = appdata[0]\n",
    "appY = appdata[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c550fb2",
   "metadata": {},
   "source": [
    "On s'intéresse à la répartition des labels dans les données. Une personne parle-t-elle beaucoup plus que l'autre ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cdc5dce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le nombre de lignes prononcées par Chirac :\t 49890\n",
      "Le nombre de lignes prononcées par Mitterrand :\t 7523 \n",
      "\n",
      "Proportion de Chirac dans la base d'apprentissage :\t 86.89669587027329 %\n",
      "Proportion de Mitterrand dans la base d'apprentissage :\t 13.103304129726718 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Le nombre de lignes prononcées par Chirac :\\t\", str(appY.count(1)))\n",
    "print(\"Le nombre de lignes prononcées par Mitterrand :\\t\", str(appY.count(-1)), \"\\n\")\n",
    "print(\"Proportion de Chirac dans la base d'apprentissage :\\t\", str((appY.count(1) / len(appY)) * 100), \"%\")\n",
    "print(\"Proportion de Mitterrand dans la base d'apprentissage :\\t\", str((appY.count(-1) / len(appY)) * 100), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685bd03a",
   "metadata": {},
   "source": [
    "On remarque donc qu'il y a presque 87% des lignes dans la base de données d'apprentissage ayant été prononcées par Mitterrand. Il se peut que cette différence puisse jouer un rôle important lors de l'apprentissage.\n",
    "\n",
    "### Nettoyage des données et analyse avancée\n",
    "\n",
    "On effectue alors un premier nettoyage des données en supprimant les chiffres, la ponctuation, les accents, les majuscules et les stopwords de la langue française.\n",
    "\n",
    "La liste des stopwords utilisés est la fusion entre la liste de la libraire nltk.stopwords et spacy.lang.fr.stop_words.\n",
    "\n",
    "Le stemmer Snowball est tiré de la librairie nltk.stem.snowball."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "40a095d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "appX = appdata[0]\n",
    "appY = appdata[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f325440d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m Sans aucune modification, on obtient comme premières lignes : \u001b[0m\n",
      "\t  Quand je dis chers amis, il ne s'agit pas là d'une formule diplomatique, mais de l'expression de ce que je ressens.\n",
      "\n",
      "\t  D'abord merci de cet exceptionnel accueil que les Congolais, les Brazavillois, nous ont réservé cet après-midi.\n",
      "\n",
      "\t  C'est toujours très émouvant de venir en Afrique car c'est probablement l'une des rares terres du monde où l'on ait conservé cette convivialité, cette amitié, ce respect de l'autre qui s'expriment avec chaleur, avec spontanéité et qui réchauffent le coeur de ceux qui arrivent et de ceux qui reçoivent.\n",
      "\n",
      "\t  Aucun citoyen français ne peut être indifférent à un séjour à Brazzaville.\n",
      "\n",
      "\t  Le Congo, que naguère le <nom> qualifia de \"refuge pour la liberté\", de \"base de départ pour la libération\", de \"môle pour la Résistance\", comment ne pas être heureux de s'y retrouver ?\n",
      "\n",
      "\n",
      "\u001b[1m Sans suppression des stopwords et sans stemming, on obtient comme premières lignes : \u001b[0m\n",
      "\t  quand je dis chers amis  il ne s agit pas la d une formule diplomatique  mais de l expression de ce que je ressens  \n",
      "\t  d abord merci de cet exceptionnel accueil que les congolais  les brazavillois  nous ont reserve cet apres midi  \n",
      "\t  c est toujours tres emouvant de venir en afrique car c est probablement l une des rares terres du monde ou l on ait conserve cette convivialite  cette amitie  ce respect de l autre qui s expriment avec chaleur  avec spontaneite et qui rechauffent le coeur de ceux qui arrivent et de ceux qui recoivent  \n",
      "\t  aucun citoyen francais ne peut etre indifferent a un sejour a brazzaville  \n",
      "\t  le congo  que naguere le  nom  qualifia de  refuge pour la liberte   de  base de depart pour la liberation   de  mole pour la resistance   comment ne pas etre heureux de s y retrouver   \n",
      "\n",
      "\u001b[1m Avec suppression des stopwords et sans stemming, on obtient comme premières lignes : \u001b[0m\n",
      "\t dis chers amis agit formule diplomatique expression ressens\n",
      "\t exceptionnel accueil congolais brazavillois reserve midi\n",
      "\t emouvant venir afrique probablement rares terres monde conserve convivialite amitie respect expriment chaleur spontaneite rechauffent coeur arrivent recoivent\n",
      "\t aucun citoyen francais indifferent sejour brazzaville\n",
      "\t congo naguere nom qualifia refuge liberte base depart liberation mole resistance heureux retrouver\n",
      "\n",
      "\u001b[1m Sans suppresion des stopwords et avec stemming, on obtient comme premières lignes : \u001b[0m\n",
      "\t quand je dis cher amis il ne s agit pas la d une formul diplomat mais de l express de ce que je ressen\n",
      "\t d abord merc de cet exceptionnel accueil que le congol le brazavillois nous ont reserv cet apre mid\n",
      "\t c est toujour tre emouv de ven en afriqu car c est probabl l une de rar terr du mond ou l on ait conserv cet convivialit cet amit ce respect de l autr qui s expriment avec chaleur avec spontaneit et qui rechauffent le coeur de ceux qui arrivent et de ceux qui recoivent\n",
      "\t aucun citoyen franc ne peut etre indifferent a un sejour a brazzavill\n",
      "\t le congo que naguer le nom qualifi de refug pour la libert de bas de depart pour la liber de mol pour la resist comment ne pas etre heureux de s y retrouv\n",
      "\n",
      "\u001b[1m Avec suppression des stopwords et un stemming, on obtient comme premières lignes : \u001b[0m\n",
      "\t dis cher amis agit formul diplomat express ressen\n",
      "\t exceptionnel accueil congol brazavillois reserv mid\n",
      "\t emouv ven afriqu probabl rar terr mond conserv convivialit amit respect expriment chaleur spontaneit rechauffent coeur arrivent recoivent\n",
      "\t aucun citoyen franc indifferent sejour brazzavill\n",
      "\t congo naguer nom qualifi refug libert bas depart liber mol resist heureux retrouv\n"
     ]
    }
   ],
   "source": [
    "print('\\033[1m', \"Sans aucune modification, on obtient comme premières lignes :\",'\\033[0m')\n",
    "for s in appX[:5] :\n",
    "    print(\"\\t\", s)\n",
    "print()\n",
    "\n",
    "test1AppX = ut.transform(appX, punc=True, accentMaj=True, nb=True, stopW=False, stem=False)\n",
    "print('\\033[1m', \"Sans suppression des stopwords et sans stemming, on obtient comme premières lignes :\",'\\033[0m')\n",
    "for s in test1AppX[:5] :\n",
    "    print(\"\\t\", s)\n",
    "print()\n",
    "\n",
    "test2AppX = ut.transform(appX, punc=True, accentMaj=True, nb=True, stopW=True, stem=False)\n",
    "print('\\033[1m', \"Avec suppression des stopwords et sans stemming, on obtient comme premières lignes :\", '\\033[0m')\n",
    "for s in test2AppX[:5] :\n",
    "    print(\"\\t\", s)\n",
    "print()\n",
    "\n",
    "test3AppX = ut.transform(appX, punc=True, accentMaj=True, nb=True, stopW=False, stem=True)\n",
    "print('\\033[1m', \"Sans suppresion des stopwords et avec stemming, on obtient comme premières lignes :\", '\\033[0m')\n",
    "for s in test3AppX[:5] :\n",
    "    print(\"\\t\", s)\n",
    "print()\n",
    "\n",
    "test4AppX = ut.transform(appX, punc=True, accentMaj=True, nb=True, stopW=True, stem=True)\n",
    "print('\\033[1m', \"Avec suppression des stopwords et un stemming, on obtient comme premières lignes :\",'\\033[0m')\n",
    "for s in test4AppX[:5] :\n",
    "    print(\"\\t\", s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e202ed",
   "metadata": {},
   "source": [
    "On crée un Counter allant mettre en avant les mots les plus souvent utilisés par chacun des Présidents, après nettoyage des données en fonction des paramètres selectionnés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd8532fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les 10 mots les plus utilisés par Mitterrand sont :\n",
      " ['de', 'la', 'et', 'à', 'le', 'les', 'que', 'des', 'qui', 'en'] \n",
      "\n",
      "Les 10 mots les plus utilisés par Chirac sont :\n",
      " ['de', 'la', 'et', 'à', 'les', 'le', 'des', 'que', 'en', 'qui']\n"
     ]
    }
   ],
   "source": [
    "# Création du dictionnaire et counter de mots de Mitterrand\n",
    "motsM = [appX[i] for i in range(len(appY)) if appY[i] == -1]\n",
    "motsM = (' '.join(motsM)).split()\n",
    "counterM = Counter(motsM)\n",
    "\n",
    "print(\"Les 10 mots les plus utilisés par Mitterrand sont :\\n\", [i[0] for i in counterM.most_common(10)], \"\\n\")\n",
    "\n",
    "# Creation du dictionnaire et counter de mots de Chirac\n",
    "motsC = [appX[i] for i in range(len(appY)) if appY[i] == 1]\n",
    "motsC = (' '.join(motsC)).split()\n",
    "counterC = Counter(motsC)\n",
    "\n",
    "print(\"Les 10 mots les plus utilisés par Chirac sont :\\n\", [i[0] for i in counterC.most_common(10)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3afe5e8f",
   "metadata": {},
   "source": [
    "On s'intéresse à mettre en place deux dictionnaires exclusifs pour Chirac et Mitterrand. Il s'agit de dictionnaires comportant les mots qu'ils utilisent de manière exclusive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bcdb9ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le ratio de mots exclusifs utilisés par Mitterrand est de :\t 0.3066925478943371\n",
      "Les 30 mots exclusifs les plus utilisés par Mitterrand sont :\n",
      " [\"'\", '-plan', '320', '-cadre', 'convenait', '-état', '-nature', '-rapport', 'Moi', \"l'-état\", '-entreprise', \"'Suite\", 'demeurant,', '-concours', 'Douze,', 'Bon,', 'répété', '\"mais', 'au-cours', \"',\", '340', 'vient,', 'imaginez', 'Seulement', \"'<date>',\", 'Nièvre', 'définitions', \"l'événement,\", '500000', 'direz'] \n",
      "\n",
      "Le ratio de mots exclusifs utilisés par Chirac est de :\t\t 0.6868985231062411\n",
      "Les 30 mots exclusifs les plus utilisés par Chirac sont :\n",
      " ['Messieurs,', 'mondialisation', 'Maire,', '\".', '*', \"l'État\", 'Mesdames,', '000', 'À', '\",', 'attentes', 'défi', 'lève', 'accueil', 'Madame', 'civilisations', 'constituent', 'Secrétaire', 'Légion', 'respectueux', 'Ministre,', 'Unies', 'accueillir', 'éthique', 'Gouvernement,', \"l'euro\", 'Affaires', 'XXIe', 'mondialisation.', 'superbe']\n"
     ]
    }
   ],
   "source": [
    "# Dictionnaire exclusif de Mitterrand\n",
    "excluM = copy.deepcopy(counterM)\n",
    "for w in counterC.keys() :\n",
    "    if w in excluM.keys() :\n",
    "        del excluM[w]\n",
    "        \n",
    "print(\"Le ratio de mots exclusifs utilisés par Mitterrand est de :\\t\", len(excluM.keys()) / len(counterM.keys()))\n",
    "print(\"Les 30 mots exclusifs les plus utilisés par Mitterrand sont :\\n\", [i[0] for i in excluM.most_common(30)], \"\\n\")\n",
    "\n",
    "# Dictionnaire exclusif de Chirac\n",
    "excluC = copy.deepcopy(counterC)\n",
    "for w in counterM.keys() :\n",
    "    if w in excluC.keys() :\n",
    "        del excluC[w]\n",
    "        \n",
    "print(\"Le ratio de mots exclusifs utilisés par Chirac est de :\\t\\t\", len(excluC.keys()) / len(counterC.keys()))\n",
    "print(\"Les 30 mots exclusifs les plus utilisés par Chirac sont :\\n\", [i[0] for i in excluC.most_common(30)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882a1c8f",
   "metadata": {},
   "source": [
    "On décide de supprimer les mots en communs entre Chirac et Mitterrand parmi les 30 mots les plus utilisés par chacun d'entre eux."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07ee876c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les 10 mots les plus utilisés par Mitterrand sont :\n",
      " ['il', 'se', '-', \"c'est\", 'Je', 'tout', 'sont', 'mais', 'cette', 'bien'] \n",
      "\n",
      "Les 10 mots les plus utilisés par Chirac sont :\n",
      " ['notre', 'nos', 'avec', 'se', 'sont', 'aux', 'Je', 'aussi', 'cette', 'leur']\n"
     ]
    }
   ],
   "source": [
    "counterM_smc30, counterC_smc30 = ut.suppN_sharedmostcommon(30, copy.copy(counterM), copy.copy(counterC))\n",
    "\n",
    "print(\"Les 10 mots les plus utilisés par Mitterrand sont :\\n\", [i[0] for i in counterM_smc30.most_common(10)], \"\\n\")\n",
    "print(\"Les 10 mots les plus utilisés par Chirac sont :\\n\", [i[0] for i in counterC_smc30.most_common(10)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42cf71f7",
   "metadata": {},
   "source": [
    "On remarque donc une bien meilleure différence entre les deux listes des 10 mots les plus utilisés pour chacun des Présidents, comparé à avant la suppression des mots communs partagés (suppression de 'france', 'europe', 'pays', 'faire' et autres mots).\n",
    "\n",
    "### Modèles de Machine Learning selectionnés\n",
    "\n",
    "Nous avons choisi d'utiliser les principaux modèles vus en cours et en TME, c'est-à-dire :\n",
    "- SVM linéaire (LinearSVC)\n",
    "- Naive Bayes (MultinomialNB)\n",
    "- régression logistique (LogisticRegression)\n",
    "\n",
    "Nous utiliserons donc la libraire sklearn puisqu'elle propose tous ces modèles. On importe tous les composants nécessaires de la librairie et d'autres élements utiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0535e720",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import des modèles utilisés\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Import de librairies pour le temps et la validation\n",
    "import time\n",
    "from sklearn.model_selection import cross_validate, cross_val_score, KFold\n",
    "\n",
    "# Import de libraires pour la mise en forme du texte\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e0aaff",
   "metadata": {},
   "source": [
    "Afin d'utiliser les données, il faut les mettre sous forme vectorielle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fbd1527f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilisation de la libraire CountVectorizer\n",
    "vectPres = CountVectorizer()\n",
    "Xpres = vectPres.fit_transform(appX)\n",
    "Ypres = appY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80f06c3",
   "metadata": {},
   "source": [
    "## Première campagne d'expériences\n",
    "\n",
    "Durant notre première campagne, nous nous sommes intéressés uniquement à l'utilisation des différents modèles en faisant varier quelques paramètres afin d'obtenir les meilleurs résultats comme l'utilisation ou non de la validation croisée, le nombre d'ensemble et le mélange ou non des données.\n",
    "\n",
    "### Utilisation du modèle SVM linéaire (LinearSVC)\n",
    "\n",
    "##### Sans validation croisée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "0c6bf86f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score sur les données d'entraînement : 0.9763294027485064\n",
      "Nombre de paramètres vecteur de poids du SVM : 28524 \n",
      "Vecteur de poids du SVM : [[ 1.55348538 -0.22581442  0.3904539  ... -0.33502112  0.\n",
      "  -0.42396068]]\n"
     ]
    }
   ],
   "source": [
    "# Création du classifieur\n",
    "svc = LinearSVC(max_iter=1000)\n",
    "svc.fit(Xpres, Ypres)\n",
    "\n",
    "# Liste pour sauvegarder les scores de précision\n",
    "resultSVM = []\n",
    "\n",
    "# Score sur les données\n",
    "res = svc.score(Xpres, Ypres)\n",
    "\n",
    "# Affichage des informations\n",
    "print(\"Score sur les données d'entraînement :\", res)\n",
    "print('Nombre de paramètres vecteur de poids du SVM :', len(svc.coef_[0]),'\\nVecteur de poids du SVM :', svc.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e28940",
   "metadata": {},
   "source": [
    "##### Validation croisée, KFold à n = 5, sans mélange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "3ca35269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score sur les données d'entraînement: [0.8582252  0.86972046 0.87999652 0.89487894 0.89026302] \n",
      "Précision moyenne = 0.87862\n"
     ]
    }
   ],
   "source": [
    "# Prédictions en utilisant la validation croisée sans mélange des données d'apprentissage\n",
    "svc = LinearSVC(max_iter=1000)\n",
    "\n",
    "# KFold permet de créer des sous-ensemble de données tel que à chaque itération, les sous-ensembles ait le même format\n",
    "# Il s'agit de l'équivalent de la fonction de validation croisée que l'on trouve dans le fichier iads/utils.py\n",
    "# https://machinelearningmastery.com/k-fold-cross-validation/#:~:text=Nevertheless%2C%20the%20KFold%20class%20can,with%20very%20large%20data%20samples.\n",
    "kfold = KFold(n_splits=5, shuffle=False)\n",
    "\n",
    "# Un fit est effectué lors de l'appel de la fonction cross_val_score\n",
    "scores_cv = cross_val_score(svc, Xpres, Ypres, cv=kfold)\n",
    "resultSVM.append(1 - statistics.mean(scores_cv))\n",
    "\n",
    "print(\"Score sur les données d'entraînement:\", scores_cv, \"\\nPrécision moyenne = %.5f\" % statistics.mean(scores_cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5efbe3",
   "metadata": {},
   "source": [
    "##### Validation croisée, KFold à n = 10, sans mélange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "69ed83a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score sur les données d'entraînement: [0.84343434 0.87513062 0.87008011 0.86918655 0.87998607 0.88434071\n",
      " 0.90123672 0.89705626 0.89078558 0.89200488] \n",
      "Précision moyenne = 0.88032\n"
     ]
    }
   ],
   "source": [
    "# Prédictions en utilisant la validation croisée sans mélange des données d'apprentissage\n",
    "svc = LinearSVC(max_iter=1000)\n",
    "\n",
    "kfold = KFold(n_splits=10, shuffle=False)\n",
    "scores_cv = cross_val_score(svc, Xpres, Ypres, cv=kfold)\n",
    "resultSVM.append(1 - statistics.mean(scores_cv))\n",
    "\n",
    "print(\"Score sur les données d'entraînement:\", scores_cv, \"\\nPrécision moyenne = %.5f\" % statistics.mean(scores_cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aae34ba",
   "metadata": {},
   "source": [
    "##### Validation croisée, KFold à n = 5, avec mélange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "6e8895d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score sur les données d'entraînement: [0.88626666 0.88940172 0.88887921 0.88460199 0.88730186] \n",
      "Précision moyenne = 0.88729\n"
     ]
    }
   ],
   "source": [
    "# Prédictions en utilisant la validation croisée sans mélange des données d'apprentissage\n",
    "svc = LinearSVC(max_iter=1000)\n",
    "\n",
    "kfold = KFold(n_splits=5, shuffle=True)\n",
    "scores_cv = cross_val_score(svc, Xpres, Ypres, cv=kfold)\n",
    "resultSVM.append(1 - statistics.mean(scores_cv))\n",
    "\n",
    "print(\"Score sur les données d'entraînement:\", scores_cv, \"\\nPrécision moyenne = %.5f\" % statistics.mean(scores_cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e62e79b",
   "metadata": {},
   "source": [
    "##### Validation croisée, KFold à n = 10, avec mélange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "f94f6de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score sur les données d'entraînement: [0.89184953 0.88627656 0.88749565 0.88730186 0.88852116 0.88730186\n",
      " 0.88956628 0.89287581 0.89235325 0.88329559] \n",
      "Précision moyenne = 0.88868\n"
     ]
    }
   ],
   "source": [
    "# Prédictions en utilisant la validation croisée sans mélange des données d'apprentissage\n",
    "clf = LinearSVC(max_iter=1000)\n",
    "\n",
    "kfold = KFold(n_splits=10, shuffle=True)\n",
    "scores_cv = cross_val_score(clf, Xpres, Ypres, cv=kfold)\n",
    "resultSVM.append(1 - statistics.mean(scores_cv))\n",
    "\n",
    "print(\"Score sur les données d'entraînement:\", scores_cv, \"\\nPrécision moyenne = %.5f\" % statistics.mean(scores_cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721e8aca",
   "metadata": {},
   "source": [
    "### Utilisation du modèle Naive Bayes (MultinomialNB)\n",
    "\n",
    "#### Sans validation croisée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "20600e55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score sur les données d'entraînement : 0.9158030411230906\n",
      "Nombre de paramètres vecteur de poids du SVM : 28524 \n",
      "Vecteur de poids du SVM : [[ -8.48585104  -9.69294397 -10.3553195  ... -13.85182706 -13.85182706\n",
      "  -13.85182706]]\n"
     ]
    }
   ],
   "source": [
    "# Création du classifieur\n",
    "clf = MultinomialNB()\n",
    "clf.fit(Xpres, Ypres)\n",
    "\n",
    "# Liste pour sauvegarder les scores de précision\n",
    "resultNB = []\n",
    "\n",
    "# Score sur les données\n",
    "print(\"Score sur les données d'entraînement :\", clf.score(Xpres, Ypres))\n",
    "print('Nombre de paramètres vecteur de poids du SVM :', len(clf.coef_[0]),'\\nVecteur de poids du SVM :', clf.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c84c53",
   "metadata": {},
   "source": [
    "##### Validation croisée, KFold à n = 5, sans mélange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "3a14ce39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score sur les données d'entraînement: [0.85927023 0.8664983  0.87929983 0.89757882 0.88033444] \n",
      "Précision moyenne = 0.87660\n"
     ]
    }
   ],
   "source": [
    "# Prédictions en utilisant la validation croisée sans mélange des données d'apprentissage\n",
    "clf = MultinomialNB()\n",
    "\n",
    "kfold = KFold(n_splits=5, shuffle=False)\n",
    "scores_cv = cross_val_score(clf, Xpres, Ypres, cv=kfold)\n",
    "resultNB.append(1 - statistics.mean(scores_cv))\n",
    "\n",
    "print(\"Score sur les données d'entraînement:\", scores_cv, \"\\nPrécision moyenne = %.5f\" % statistics.mean(scores_cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de5bb67",
   "metadata": {},
   "source": [
    "##### Validation croisée, KFold à n = 10, sans mélange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "f4fc8c00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score sur les données d'entraînement: [0.84691745 0.87600139 0.87617555 0.86204494 0.88416652 0.87632817\n",
      " 0.90175928 0.89148232 0.87772165 0.88346978] \n",
      "Précision moyenne = 0.87761\n"
     ]
    }
   ],
   "source": [
    "# Prédictions en utilisant la validation croisée sans mélange des données d'apprentissage\n",
    "clf = MultinomialNB()\n",
    "\n",
    "kfold = KFold(n_splits=10, shuffle=False)\n",
    "scores_cv = cross_val_score(clf, Xpres, Ypres, cv=kfold)\n",
    "resultNB.append(1 - statistics.mean(scores_cv))\n",
    "\n",
    "print(\"Score sur les données d'entraînement:\", scores_cv, \"\\nPrécision moyenne = %.5f\" % statistics.mean(scores_cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb74921",
   "metadata": {},
   "source": [
    "##### Validation croisée, KFold à n = 5, avec mélange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "9de5dab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score sur les données d'entraînement: [0.88347993 0.88914047 0.88086737 0.89069848 0.88477617] \n",
      "Précision moyenne = 0.88579\n"
     ]
    }
   ],
   "source": [
    "# Prédictions en utilisant la validation croisée sans mélange des données d'apprentissage\n",
    "clf = MultinomialNB()\n",
    "\n",
    "kfold = KFold(n_splits=5, shuffle=True)\n",
    "scores_cv = cross_val_score(clf, Xpres, Ypres, cv=kfold)\n",
    "resultNB.append(1 - statistics.mean(scores_cv))\n",
    "\n",
    "print(\"Score sur les données d'entraînement:\", scores_cv, \"\\nPrécision moyenne = %.5f\" % statistics.mean(scores_cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf837097",
   "metadata": {},
   "source": [
    "##### Validation croisée, KFold à n = 10, avec mélange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "4e3fac52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score sur les données d'entraînement: [0.88174852 0.88557994 0.88749565 0.88712768 0.88904372 0.88312141\n",
      " 0.88364396 0.88468908 0.88573419 0.88886953] \n",
      "Précision moyenne = 0.88571\n"
     ]
    }
   ],
   "source": [
    "# Prédictions en utilisant la validation croisée sans mélange des données d'apprentissage\n",
    "clf = MultinomialNB()\n",
    "\n",
    "kfold = KFold(n_splits=10, shuffle=True)\n",
    "scores_cv = cross_val_score(clf, Xpres, Ypres, cv=kfold)\n",
    "resultNB.append(1 - statistics.mean(scores_cv))\n",
    "\n",
    "print(\"Score sur les données d'entraînement:\", scores_cv, \"\\nPrécision moyenne = %.5f\" % statistics.mean(scores_cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0775551",
   "metadata": {},
   "source": [
    "### Utilisation du modèle de Regression Logistique (LogisticRegression)\n",
    "\n",
    "#### Sans validation croisée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "d83a5d7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score sur les données d'entraînement : 0.9445247592008779\n",
      "Nombre de paramètres vecteur de poids du SVM : 28524 \n",
      "Vecteur de poids du SVM : [[ 2.34084434 -0.52298687  0.13207444 ... -0.37166223 -0.02158416\n",
      "  -0.22511148]]\n"
     ]
    }
   ],
   "source": [
    "# Création du classifieur\n",
    "lin = LogisticRegression(max_iter=1000)\n",
    "lin.fit(Xpres, Ypres)\n",
    "\n",
    "# Liste pour sauvegarder les scores de précision\n",
    "resultLR = []\n",
    "\n",
    "# Score sur les données\n",
    "print(\"Score sur les données d'entraînement :\", lin.score(Xpres, Ypres))\n",
    "print('Nombre de paramètres vecteur de poids du SVM :', len(lin.coef_[0]),'\\nVecteur de poids du SVM :', lin.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93dce6d",
   "metadata": {},
   "source": [
    "##### Validation croisée, KFold à n = 5, sans mélange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf15860",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prédictions en utilisant la validation croisée sans mélange des données d'apprentissage\n",
    "lin = LogisticRegression(max_iter=1000)\n",
    "\n",
    "kfold = KFold(n_splits=5, shuffle=False)\n",
    "scores_cv = cross_val_score(lin, Xpres, Ypres, cv=kfold)\n",
    "resultLR.append(1 - statistics.mean(scores_cv))\n",
    "\n",
    "print(\"Score sur les données d'entraînement:\", scores_cv, \"\\nPrécision moyenne = %.5f\" % statistics.mean(scores_cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c818f4d",
   "metadata": {},
   "source": [
    "##### Validation croisée, KFold à n = 10,  sans mélange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f556bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prédictions en utilisant la validation croisée sans mélange des données d'apprentissage\n",
    "lin = LogisticRegression(max_iter=1000)\n",
    "\n",
    "kfold = KFold(n_splits=10, shuffle=False)\n",
    "scores_cv = cross_val_score(lin, Xpres, Ypres, cv=kfold)\n",
    "resultLR.append(1 - statistics.mean(scores_cv))\n",
    "\n",
    "print(\"Score sur les données d'entraînement:\", scores_cv, \"\\nPrécision moyenne = %.5f\" % statistics.mean(scores_cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c5dc91",
   "metadata": {},
   "source": [
    "##### Validation croisée, KFold à n = 5, avec mélange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ca3dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prédictions en utilisant la validation croisée sans mélange des données d'apprentissage\n",
    "lin = LogisticRegression(max_iter=1000)\n",
    "\n",
    "kfold = KFold(n_splits=5, shuffle=True)\n",
    "scores_cv = cross_val_score(lin, Xpres, Ypres, cv=kfold)\n",
    "resultLR.append(1 - statistics.mean(scores_cv))\n",
    "\n",
    "print(\"Score sur les données d'entraînement:\", scores_cv, \"\\nPrécision moyenne = %.5f\" % statistics.mean(scores_cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78925366",
   "metadata": {},
   "source": [
    "##### Validation croisée, KFold à n = 10, avec mélange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09fc2eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prédictions en utilisant la validation croisée sans mélange des données d'apprentissage\n",
    "lin = LogisticRegression(max_iter=1000)\n",
    "\n",
    "kfold = KFold(n_splits=10, shuffle=True)\n",
    "scores_cv = cross_val_score(lin, Xpres, Ypres, cv=kfold)\n",
    "resultLR.append(1 - statistics.mean(scores_cv))\n",
    "\n",
    "print(\"Score sur les données d'entraînement:\", scores_cv, \"\\nPrécision moyenne = %.5f\" % statistics.mean(scores_cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa56b0f4",
   "metadata": {},
   "source": [
    "### Affichage et comparaisons des données\n",
    "\n",
    "Maintenant que nous avons récupérer tous les scores de précision moyenne, nous allons désormais les comparer afin de réaliser de premières observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9dda2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regroupement des résultats\n",
    "xlabels = [\"crossval, n=5, no shuffle\", \"crossval, n=5, shuffle\", \n",
    "           \"crossval, n=10, no shuffle\", \"crossval, n=10, shuffle\"]\n",
    "x = np.arange(4)\n",
    "\n",
    "# Création du graphique\n",
    "plt.figure(figsize=(8, 4))\n",
    "ax = plt.subplot(111)\n",
    "\n",
    "# Mise en place des informations\n",
    "ax.bar(x - 0.1, resultSVM, width=0.1, color='g', align='center', label=\"LinearSVC\")\n",
    "ax.bar(x, resultNB, width=0.1, color='r', align='center', label=\"MultinomialNB\")\n",
    "ax.bar(x + 0.1, resultLR, width=0.1, color='b', align='center', label=\"LogisticRegression\")\n",
    "ax.set_xlabel('All models and settings', fontsize=10)\n",
    "ax.set_ylabel('Mean Loss', fontsize=10)\n",
    "plt.title('Mean losses of different models and settings')\n",
    "plt.xticks(x, xlabels, fontsize=8)\n",
    "\n",
    "# Mise en place de la légende\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 1))\n",
    "\n",
    "# Affichage et sauvegarde\n",
    "plt.savefig('first_exp_cmp.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47dac79c",
   "metadata": {},
   "source": [
    "On remarque que le modèle le plus précis est la Regression Logistique, puisque son taux d'erreur moyen est constamment inférieur ou égal à 10%. On remarque tout de même qu'en augmentant le nombre d'itérations\n",
    "\n",
    "## Deuxième campagne d'expériences\n",
    "\n",
    "Nous avons évoqué précedemment le fait que chaque Président utilise plus souvent certains mots que d'autres"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b61816",
   "metadata": {},
   "source": [
    "## Troisième campagne d'expériences\n",
    "\n",
    "### Recherche des meilleurs paramètres par GridSearch\n",
    "\n",
    "On ne peut pas essayer chaque combinaison de paramètres à la main, il faut donc mettre en place un GridSearch avec tous les paramètres utilisés afin de trouver la meilleure.\n",
    "\n",
    "On crée un dictionnaire allant contenir tous les champs de paramètres et valeurs possibles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403b7bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionnaire de paramètres globaux\n",
    "mainParameters = {\"processing\" : \n",
    "                  { \"punc\": [False, True],\n",
    "                    \"accentMaj\": [False, True],\n",
    "                    \"nb\": [False, True],\n",
    "                    \"stopW\": [False, True],\n",
    "                    \"stem\": [False, True] },\n",
    "                  }\n",
    "\n",
    "# \n",
    "\n",
    "# Création des Vectorizer\n",
    "# CountVectorizer\n",
    "vectorizerC_pres = CountVectorizer()\n",
    "vectorizerC_pres1G = CountVectorizer(ngram_range=(1,1))\n",
    "vectorizerC_pres2G = CountVectorizer(ngram_range=(2,2))\n",
    "vectorizerC_pres12G = CountVectorizer(ngram_range=(1,2))\n",
    "vectorizerC_pres13G = CountVectorizer(ngram_range=(1,3))\n",
    "vectorizerC_pres3G = CountVectorizer(ngram_range=(3,3))\n",
    "\n",
    "vectorizerTFIDF_pres = TfidfVectorizer()\n",
    "vectorizerTFIDF_pres1G = TfidfVectorizer(ngram_range=(1,1))\n",
    "vectorizerTFIDF_pres2G = TfidfVectorizer(ngram_range=(2,2))\n",
    "vectorizerTFIDF_pres12G = TfidfVectorizer(ngram_range=(1,2))\n",
    "vectorizerTFIDF_pres13G = TfidfVectorizer(ngram_range=(1,3))\n",
    "vectorizerTFIDF_pres3G = TfidfVectorizer(ngram_range=(3,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d1c445",
   "metadata": {},
   "source": [
    "Les combinaisons de paramètres maintenant créées, on peut s'attaquer à la réalisation du GridSearch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "71e4f769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combinaison : 464 / 6336\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5400/1799217659.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[1;31m# Utilisation de la fonction ut.transforme pour formater les données\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[0mappX_t\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mut\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mappX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'processing'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[1;31m# Initialisation du modèle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Almehdi\\Documents\\UPMC\\M1_DAC\\S2\\RITAL\\ProjetTAL\\iads\\utils.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(text, punc, accentMaj, nb, stopW, stem)\u001b[0m\n\u001b[0;32m     80\u001b[0m         \u001b[1;31m# Utilisation des racines\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mstem\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 82\u001b[1;33m             \u001b[0mtext_transf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m' '\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfrStemmer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtext_transf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtext_transf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Almehdi\\Documents\\UPMC\\M1_DAC\\S2\\RITAL\\ProjetTAL\\iads\\utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     80\u001b[0m         \u001b[1;31m# Utilisation des racines\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mstem\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 82\u001b[1;33m             \u001b[0mtext_transf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m' '\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfrStemmer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtext_transf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtext_transf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Code permettant de réaliser le GridSearch\n",
    "\n",
    "# Création du dictionnaire afin de créer un DataFrame\n",
    "df = dict()\n",
    "\n",
    "# On ouvre le fichier contenant les configurations\n",
    "with open(\"model_results.txt\", 'w') as f:\n",
    "    \n",
    "    # On parcourt chaque ligne du fichier\n",
    "    for it in range(len(paramsComb)) :\n",
    "        print(\"Combinaison :\", it + 1, \"/\", len(paramsComb), end='\\r')\n",
    "           \n",
    "        # On récupère la configuration à utiliser\n",
    "        params = paramsComb[it]\n",
    "                \n",
    "        # Utilisation de la fonction ut.transforme pour formater les données\n",
    "        appX_t = ut.transform(appX, **params['processing'])\n",
    "            \n",
    "        # Initialisation du modèle\n",
    "        m = params['model']['m']\n",
    "        if (m == MultinomialNB) :\n",
    "            model = MultinomialNB()\n",
    "        elif (m == LinearSVC) :\n",
    "            model = LinearSVC(C = params['cross_val']['C'])\n",
    "        else :\n",
    "            model = LogisticRegression(C = params['cross_val']['C'])\n",
    "                    \n",
    "        # Représentation sous forme vectorielle\n",
    "        if (params['vectorizer']['type'] == CountVectorizer) :\n",
    "            vectorizer = CountVectorizer()\n",
    "        else :\n",
    "            vectorizer = TfidfVectorizer()\n",
    "        X = vectorizer.fit_transform(appX_t)\n",
    "\n",
    "        # Cross-validation\n",
    "        kfold = KFold(n_splits=2, shuffle=True)\n",
    "        scores = cross_validate(model, X, appY, cv=kfold, scoring=['accuracy','f1'])\n",
    "        accuracy = np.mean(scores['test_accuracy'])\n",
    "        f1 = np.mean(scores['test_f1'])\n",
    "                    \n",
    "        # Ecriture du score dans le fichier de sortie\n",
    "        f.write('{} {} {}\\n' . format(it, accuracy, f1))\n",
    "                \n",
    "        # Ecriture dans un dictionnaire pour l'affichage DataFrame\n",
    "        line = params\n",
    "        line['model']['m'] = str(line['model']['m'])\n",
    "        line['vectorizer']['type'] = str(line['vectorizer']['type'])\n",
    "                \n",
    "        df[it] = [it] + [i for k, v in line.items() for i in v.values()]\n",
    "        df[it].append(accuracy)\n",
    "\n",
    "# On place le resultat dans un dataframe Pandas afin de faciliter son exploitation par la suite\n",
    "res = pd.DataFrame.from_dict(df, orient='index', columns=['selected line', 'lowercase and no accents', 'no numbers', 'no punctuation', 'stemming', 'no stopwords', 'ngram', 'vectorizer', 'model', 'regularization factor', 'score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28dd25b8",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
